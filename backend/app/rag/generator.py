from __future__ import annotations

from typing import List, Tuple, Any, Dict, Union

from app.services.openai_client import get_client
from app.config import settings
from app.services.logging import get_logger
from app.models.schemas import Chunk, ScoredChunk  # â† ê²½ë¡œ ì£¼ì˜!

log = get_logger("app.rag.generator")


def _score_of(sc: Union[ScoredChunk, Chunk]) -> float:
    """ì •ë ¬ ì ìˆ˜ í†µì¼: ScoredChunkë©´ score/similarity/(1-distance) ìš°ì„ ìˆœìœ„ ì‚¬ìš©, Chunkë©´ 0."""
    if isinstance(sc, ScoredChunk):
        # pydantic v2: hasattrë¡œ ì ‘ê·¼
        if hasattr(sc, "score") and isinstance(sc.score, (int, float)):
            return float(sc.score)
        if hasattr(sc, "similarity") and isinstance(sc.similarity, (int, float)):
            return float(sc.similarity)
        if hasattr(sc, "distance") and isinstance(sc.distance, (int, float)):
            d = max(0.0, min(1.0, float(sc.distance)))
            return 1.0 - d
    return 0.0


def _as_chunk(x: Union[ScoredChunk, Chunk]) -> Chunk:
    """ScoredChunk â†’ Chunk, ì´ë¯¸ Chunkë©´ ê·¸ëŒ€ë¡œ."""
    if isinstance(x, ScoredChunk):
        return x.chunk
    return x


def _select_chunks(
    candidates: List[Union[ScoredChunk, Chunk]], max_chars: int = 6000
) -> List[Chunk]:
    """
    ì»¨í…ìŠ¤íŠ¸ì— ë„£ì„ ì²­í¬ ì„ ë³„.
    - ì ìˆ˜ ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬
    - max_charsë¥¼ ë„˜ì§€ ì•ŠëŠ” ì„ ì—ì„œ ëˆ„ì 
    ë°˜í™˜ì€ í•­ìƒ List[Chunk]
    """
    # ì •ë ¬ (ì ìˆ˜ ë†’ì€ ìˆœ)
    ordered = sorted(candidates, key=_score_of, reverse=True)

    picked: List[Chunk] = []
    total = 0
    for c in ordered:
        ch = _as_chunk(c)
        text = ch.content or ""
        l = len(text)
        if l == 0:
            continue
        if total + l > max_chars and picked:
            break
        picked.append(ch)
        total += l

    return picked


def _build_context(chunks: List[Chunk]) -> str:
    """í”„ë¡¬í”„íŠ¸ì— ë„£ì„ ì»¨í…ìŠ¤íŠ¸ ë¬¸ìì—´ êµ¬ì„±."""
    lines: List[str] = []
    for i, ch in enumerate(chunks, start=1):
        title = ch.doc_title or ch.doc_id or "Untitled"
        lines.append(
            f"[{i}] {title} (doc_type={ch.doc_type}, visibility={ch.visibility}, tags={','.join(ch.tags or [])})"
        )
        lines.append(ch.content.strip())
        lines.append("")  # ë¹ˆ ì¤„
    return "\n".join(lines).strip()


async def generate_answer(
    question: str, candidates: List[Union[ScoredChunk, Chunk]]
) -> Tuple[str, List[Chunk]]:
    """
    ì§ˆë¬¸ + í›„ë³´ ì²­í¬ë“¤ë¡œ ë‹µë³€ ìƒì„±.
    ë°˜í™˜: (answer_text, used_chunks)
    """
    used_chunks: List[Chunk] = _select_chunks(candidates, max_chars=6000)
    context = _build_context(used_chunks)

    system_msg = (
        "ë„ˆëŠ” ì§ˆë¬¸ì— ëŒ€í•´ ëª…í™•í•˜ê³  êµ¬ì¡°ì ìœ¼ë¡œ ë‹µë³€í•˜ëŠ” ì‚¬ë‚´ ê·œì • ì•ˆë‚´ ë¹„ì„œë‹¤.\n\n"
        "### ë‹µë³€ í˜•ì‹ ê·œì¹™:\n"
        "1. ë‹µë³€ì€ í•­ìƒ ì§ˆë¬¸ì— ëŒ€í•œ í•µì‹¬ ê²°ë¡ ì„ ì²« ë¬¸ì¥ìœ¼ë¡œ ì œì‹œí•´ì•¼ í•œë‹¤.\n"
        "2. ê·¸ ë‹¤ìŒ, **ê¸€ë¨¸ë¦¬ ê¸°í˜¸(bullet points)**ë‚˜ ë²ˆí˜¸ ëª©ë¡ì„ ì‚¬ìš©í•˜ì—¬ êµ¬ì²´ì ì¸ ë‚´ìš©ì„ ì²´ê³„ì ìœ¼ë¡œ ì„¤ëª…í•´ë¼.\n"  # ğŸ’¡ ìˆ˜ì •ëœ ë¶€ë¶„
        "3. ë‹µë³€ì˜ ì œëª©ì´ë‚˜ ì „ì²´ ë¬¸ì¥ì— ë¶ˆí•„ìš”í•œ ê°•ì¡°(**)ë¥¼ ì‚¬ìš©í•˜ì§€ ë§ˆë¼. ê°•ì¡°ëŠ” ë°˜ë“œì‹œ ì„¤ëª…ì— í•„ìš”í•œ í•µì‹¬ ìš©ì–´ë‚˜ íŠ¹ì • í•­ëª©ì—ë§Œ ìµœì†Œí•œìœ¼ë¡œ ì‚¬ìš©í•´ì•¼ í•œë‹¤.\n\n"
        "### ë‚´ìš© ê·œì¹™:\n"
        "1. ì£¼ì–´ì§„ ìë£Œ(ì»¨í…ìŠ¤íŠ¸)ì— ëª…ì‹œëœ ë‚´ìš©ë§Œì„ ê·¼ê±°ë¡œ, ì •í™•í•œ ì‚¬ì‹¤ì„ í•œêµ­ì–´ë¡œ ì „ë‹¬í•´ì•¼ í•œë‹¤.\n"
        "2. ê·¼ê±°ê°€ ë¶ˆì¶©ë¶„í•˜ë©´ 'ì œê³µëœ ìë£Œë§Œìœ¼ë¡œëŠ” ì •í™•íˆ ë‹µë³€í•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤'ë¼ê³  ë§í•˜ê³ , ì¶”ê°€ë¡œ í™•ì¸í•´ì•¼ í•  ì‚¬í•­ì„ ì œì•ˆí•´ë¼."
    )

    user_msg = (
        f"ì§ˆë¬¸:\n{question}\n\n"
        f"ë‹¤ìŒì€ ê²€ìƒ‰ëœ ê´€ë ¨ ë¬¸ì„œ ì²­í¬ë“¤ì´ë‹¤. "
        f"ì´ ì •ë³´ë§Œ ì‚¬ìš©í•´ì„œ ë‹µë³€í•´ë¼.\n\n"
        f"{context}"
    )

    client = get_client()
    # Chat Completions (v1 ì—”ë“œí¬ì¸íŠ¸ ì‚¬ìš©)
    resp = client.chat.completions.create(
        model=settings.openai_model,
        messages=[
            {"role": "system", "content": system_msg},
            {"role": "user", "content": user_msg},
        ],
        temperature=0.2,
    )
    answer = resp.choices[0].message.content.strip() if resp.choices else ""

    return answer, used_chunks

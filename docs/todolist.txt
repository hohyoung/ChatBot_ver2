P0 — 반드시 먼저(정확성·속도·신뢰성의 기반)
1) 문서 열람·검색 페이지 (문서 리스트 + 미리보기 + 다운로드)

왜: 유저가 올린 문서를 직접 찾아보고 확인해야 Q/A 신뢰가 유지됨.

어떻게: 연도/분류/태그/업로더/전문검색(키워드) 필터 + 카드/테이블 보기, 미리보기(요약/첫 페이지/메타) 제공.
챗봇 질의로도 “문서 찾아줘”류 요청 시 문서 결과 리스트를 반환.

AC: (a) 필터·검색 정확, (b) 미리보기/다운로드 동작, (c) 1초 내 리스트 표출(캐시 기준).

의존성: 3) 인입 파이프라인/인덱스, 2) 오케스트레이터.

2) 오케스트레이터(GAR) — 문서요청 vs 내용질문 Intent 라우팅

왜: 매번 전체 문서로 답변하면 느리고 비싸다. 의도에 맞게 빠른 경로 선택 필요.

어떻게:

의도 판별: doc_request (문서를 원함) / info_request (내용 요약·답변)

info_request: 마스터 인덱스 → 상위 3개 문서 → 핵심 문단 압축 후 LLM

doc_request: 문서 열람 페이지용 문서 리스트 반환(메타+스코어)

AC: 100개 샘플 질의에서 의도 판별 정확도 ≥95%, 모든 답변에 sources 포함.

의존성: 3) 인덱스/임베딩, 6) JSON/근거.

3) 인입 파이프라인: DOCX→MD + 마스터 인덱스(용어·조항)

왜: 빠른 후보 선별(정확·저비용)의 핵심은 좋은 인덱스.

어떻게: DOCX 변환(이미지 분리), 섹션/조항/용어 추출 → index_master 생성/증분 갱신.

AC: 신규 문서 투입 후 N분 내 인덱스 반영, 인덱스 미스율 ↓.

의존성: 1), 2).

4) 스트리밍 응답(stream:true) — UX 체감속도 개선

왜: 사용자는 “기다림”보다 “진행 중”을 원함. 첫 토큰 지연을 줄여 만족도↑.

어떻게: 서버 SSE/WebSocket 스트리밍, 프런트 토큰 단위 렌더(타이핑 효과) + 중간 근거 미리 노출.

AC: 첫 토큰 ≤2s(캐시 적중 시), 전체 p50 ≤15s / p90 ≤22s.

의존성: 2) 오케스트레이터, 8) 성능.

5) 보안: 사내 메일 인증(업로드 제한)

왜: 외부 문서 유입 차단 → 지식 베이스 신뢰 확보.

어떻게: 도메인 화이트리스트 + 이메일 OTP/SSO + 업로드/관리 라우트 RBAC.

AC: 비사내 계정 업로드 100% 차단(401/403), 감사 로그 기록.

의존성: 1), 3).

6) 출력 일관성 & 근거 강제 — JSON 스키마 + 페르소나 + sources[]

왜: 응답을 UI·감사에 바로 쓰려면 스키마가 필수. 규정 챗봇은 근거 인용이 신뢰 핵심.

어떻게: 시스템 프롬프트에 스키마/톤/조항 표기 규칙 고정, 결과를 JSON 검증 후 전달.

AC: 100건 중 JSON 유효성 100%, 모든 답변에 최소 1개 이상의 근거.

의존성: 2), 3).

7) 큐잉·재시도 + API 키 라운드로빈

왜: 동시성에서 요청 유실·429 방지, 안정적인 처리량 보장.

어떻게: 작업 큐(재시도/백오프/멱등키), 키풀 라운드로빈 + 사용량 모니터링.

AC: 부하(동시 100)에서 실패율 <0.5%, 429 비율 <1%.

의존성: 2), 4).

8) 성능 목표 달성(15–20초) — 캐시·압축·상한

왜: 현장 목표. 느리면 실제 사용이 줄어듦.

어떻게: 후보 문서 상한=3, 문단 압축, 임베딩/검색/파일 캐시, 동일질의 de-dup.

AC: p50 ≤15s / p90 ≤22s(샘플 200건), 비용/토큰 지표 집계.

의존성: 2), 3), 4), 7).

9) 감사 로그 & 모니터링

왜: 재현성과 품질 개선, 보안/컴플라이언스 대응.

어떻게: Q/A, sources, 지연, 키 사용, 의도·경로 선택 로그(JSONL/DB) + 대시보드.

AC: 모든 요청 트레이스 가능, 주간 리포트 자동 산출.

의존성: 6), 7), 8).

P1 — 정확도/UX 고도화
10) 표/그림 인식 → 텍스트 청크화

왜: 표/양식이 많은 규정에서 정답률·인용률↑.

어떻게: 이미지 추출 → OCR/비전 → 마크다운 표·구조화 텍스트 + 메타(table_schema, figure_id).

AC: 표 기반 질의 정답률/근거 인용률 유의미 개선.

의존성: 3).

11) 오타 교정 & 제안형 응답

왜: 사내 용어/조항 오타로 검색 실패 방지.

어떻게: 편집거리+도메인 사전 기반 교정 후보 → “오타로 추정… ‘교정어’ 기준 답변” 동시 제시.

AC: 의도적 오타 30케이스에서 정정 적중 ≥90%.

의존성: 3).

12) FAQ 자동 축적 & 카드 노출

왜: 반복 질문 즉시 응답 → 체감 속도↑.

어떻게: 질문 로그 클러스터링 → Top-N FAQ 인덱스 → 사이드바/검색 상단 노출.

AC: 최근 7일 Top-N 자동 갱신, 클릭→3초 내 응답.

13) UX 경량화 & 마크다운 출력

왜: 체감 성능·가독성 개선. 챗봇 답변의 시인성 향상으로 사용자 이해도 증가.

어떻게:
- 스켈레톤 로딩
- 근거 접기/펼치기
- 모바일 폰트/레이아웃 정리
- **챗봇 답변 마크다운 렌더링**: 헤딩, 볼드, 리스트, 코드블록, 테이블 등 서식 지원
- 답변 내 조항/섹션 강조 표시 (하이라이트)

AC:
- 사용성 테스트 만족도 >80%
- 마크다운 렌더링 정확도 100% (일반 서식 기준)
- 답변 내 구조화된 정보(리스트, 테이블) 가독성 테스트 통과

P2 — 운영·배포
14) 관리자 페이지 — 재인덱스/캐시·키 상태/FAQ 관리 (+외부 파일 TTL 리프레시)

왜: 코드 수정 없이 운영 통제.

어떻게: 재인덱스·캐시 플러시·키 상태·FAQ 고정/숨김, 48h 리프레시 버튼/스케줄러.

AC: UI만으로 운영 필수 작업 수행 가능.

15) CI/CD(Jenkins 등)

왜: 속도·품질·일관성.

어떻게: PR 테스트→빌드→스테이징→승인→프로덕 자동 배포.

AC: main 머지 시 스테이징 자동, 태그 시 프로덕 반영.

의존성 맵(요약)

3(인입/인덱스) → 2(오케스트레이션) → 4(스트리밍), 8(성능)

6(JSON/근거) → 9(감사), 12(FAQ)

1(문서열람) ↔ 2(오케스트레이션) (doc_request 경로)

7(큐/키풀) → 4/8(안정적 성능)

권장 마일스톤(문서화/개발 기준)

M1 (P0 코어): 1,2,3,4,5,6,7,8,9

M2 (정확도·UX): 10,11,12,13

M3 (운영·배포): 14,15

PRD/LLD/PLAN로 확장할 때 넣을 최소 항목(힌트)

PRD: 문제정의, KPI(정확도/속도/채택률), 핵심 시나리오(문서요청/내용질문), NFR(응답 p50/p90, 가용성, 보안)

LLD: 오케스트레이터 플로우차트, 인덱스 스키마, 스트리밍 프로토콜(SSE/WS), JSON 응답 스키마, 로그 스키마

PLAN: M1~M3 일정/리소스, 위험/완화(429, 캐시 만료), 릴리즈 체크리스트(AC 기반)